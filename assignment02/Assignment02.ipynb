{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COSC 426 / 526 - Assignment 02\n",
    "### Discussed: Jan 31, 2025\n",
    "### Due:  Feb 7, 2025 before 8AM ET\n",
    "---\n",
    "This notebook contains essential functions for your assignment. You will need to enhance and write additional code to complete the tasks. Please submit your completed work to the designated GitHub repository.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "This task involves processing files containing [delimiter-separated values](https://en.wikipedia.org/wiki/Delimiter-separated_values). We will focus on two formats: [comma-separated values](https://en.wikipedia.org/wiki/Comma-separated_values) (CSV) and [tab-separated values](https://en.wikipedia.org/wiki/Tab-separated_values) (TSV).\n",
    "\n",
    "## Problem 1a: Handling Comma-Separated Values (CSV)\n",
    "\n",
    "A CSV file, as defined by [Wikipedia](https://en.wikipedia.org/wiki/Comma-separated_values), is a plain text format used to store tabular data. Each line in a CSV file represents a data record, with individual fields separated by commas. The first line usually contains headers naming each column.\n",
    "\n",
    "For the CSV processing part of this task, you are required to:\n",
    "\n",
    "Count and display the number of data rows in the CSV file, excluding the header row.\n",
    "\n",
    "Count and display the number of columns in the CSV file.\n",
    "\n",
    "Calculate and display the average age from the values in the \"age\" column. Assume all ages in the file are integers, but compute the average as a floating-point number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows of data: 8\n",
      "Number of cols: 3\n",
      "Average Age: 70.875\n"
     ]
    }
   ],
   "source": [
    "def parse_delimited_file(filename, delimiter=\",\"):\n",
    "    # Open and read in all lines of the file\n",
    "    # (I do not recommend readlines for LARGE files)\n",
    "    # `open`: ref [1]\n",
    "    # `readlines`: ref [2]\n",
    "    with open(filename, 'r', encoding='utf8') as dsvfile:\n",
    "        lines = dsvfile.readlines()\n",
    "\n",
    "    # Strip off the newline from the end of each line\n",
    "    # Using list comprehension is the recommended pythonic way to iterate through lists\n",
    "    # HINT: refs [3,4]\n",
    "    lines = [line.rstrip() for line in lines]\n",
    "\n",
    "    # Split each line based on the delimiter (which, in this case, is the comma)\n",
    "    # HINT: ref [5]\n",
    "    lines = [line.split(delimiter) for line in lines]\n",
    "    \n",
    "    # Separate the header from the data\n",
    "    # HINT: ref [6]\n",
    "    header = lines[0]\n",
    "    lines = lines[1:]\n",
    "\n",
    "\n",
    "    # Find \"age\" within the header\n",
    "    # (i.e., calculating the column index for \"age\")\n",
    "    # HINT: ref [7]\n",
    "    age_index = header.index(\"age\")\n",
    "\n",
    "    # Calculate the number of data rows and columns\n",
    "    # HINT: [8]\n",
    "    num_data_rows = len(lines)\n",
    "    num_data_cols = len(lines[0])\n",
    "    \n",
    "    # Sum the \"age\" values\n",
    "    # HINT: ref [9]\n",
    "    age_total = 0\n",
    "    for line in lines:\n",
    "        age_total += int(line[age_index])\n",
    "        \n",
    "    # Calculate the average age\n",
    "    ave_age = age_total / num_data_rows\n",
    "    \n",
    "    # Print the results\n",
    "    # `format`: ref [10]\n",
    "    print(\"Number of rows of data: {}\".format(num_data_rows))\n",
    "    print(\"Number of cols: {}\".format(num_data_cols))\n",
    "    print(\"Average Age: {}\".format(ave_age))\n",
    "    \n",
    "# Parse the provided csv file\n",
    "parse_delimited_file('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Ouput:**\n",
    "```\n",
    "Number of rows of data: 8\n",
    "Number of cols: 3\n",
    "Average Age: 70.875\n",
    "```\n",
    "**References:**\n",
    "- [1: open](https://docs.python.org/3.6/library/functions.html#open)\n",
    "- [2: readlines](https://docs.python.org/3.6/library/codecs.html#codecs.StreamReader.readlines)\n",
    "- [3: list comprehension](https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions)\n",
    "- [4: rstrip](https://docs.python.org/3.6/library/stdtypes.html#str.rstrip)\n",
    "- [5: split](https://docs.python.org/3.6/library/stdtypes.html#str.split)\n",
    "- [6: splice](https://docs.python.org/3.6/glossary.html#term-slice)\n",
    "- [7: \"more on lists\"](https://docs.python.org/3.6/tutorial/datastructures.html#more-on-lists)\n",
    "- [8: len](https://docs.python.org/3.6/library/functions.html#len)\n",
    "- [9: int](https://docs.python.org/3.6/library/functions.html#int)\n",
    "- [10: format](https://docs.python.org/3.6/library/stdtypes.html#str.format)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1b: Analyzing Tab-Separated Values (TSV)\n",
    "\n",
    "Based on information from [Wikipedia](https://en.wikipedia.org/wiki/Tab-separated_values), a TSV file is a straightforward text format used for storing data in a table-like structure, such as in databases or spreadsheets. In such files, each line represents a data record, and individual fields within a record are separated by tab characters. This makes TSV a specific example of the wider category of delimiter-separated values formats.\n",
    "\n",
    "For this task, you need to apply the same analysis as you did in the previous exercise, but this time using the provided tab-delimited file.\n",
    "\n",
    "**Important Note:** The column arrangement in this new file differs from before. If your earlier approach involved hardcoding the position of the \"age\" column, you'll need to revise the `parse_delimited_file` function file that includes an \"age\" column, regardless of the column's order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows of data: 8\n",
      "Number of cols: 3\n",
      "Average Age: 70.875\n"
     ]
    }
   ],
   "source": [
    "# Further reading on optional arguments, like \"delimiter\": http://www.diveintopython.net/power_of_introspection/optional_arguments.html\n",
    "parse_delimited_file('data.tsv', delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Ouput:**\n",
    "```\n",
    "Number of rows of data: 8\n",
    "Number of cols: 3\n",
    "Average Age: 70.875\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Converting Unicode to ASCII in Python\n",
    "\n",
    "Upon examining the `data.csv` file, you might have noticed names containing non-English characters. These are encoded using [Unicode](https://en.wikipedia.org/wiki/Unicode), a comprehensive standard for representing a vast array of text characters and symbols. Python 3 [natively supports](https://docs.python.org/3/howto/unicode.html) offers built-in support for Unicode, but not all tools are compatible with it. Some require text in the [ASCII](https://en.wikipedia.org/wiki/ASCII) format.\n",
    "\n",
    "Your task is to convert the Unicode-formatted names from the file into ASCII-formatted names and save these names into a new file named `data-ascii.txt`, placing each name on a separate line. To facilitate this conversion, use the provided [tranliteration dictionary](https://german.stackexchange.com/questions/4992/conversion-table-for-diacritics-e-g-%C3%BC-%E2%86%92-ue), which maps several common Unicode characters to their ASCII equivalents. Employ this dictionary to transform the Unicode strings into ASCII format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Richard Phillips Feynman\n",
      "Shin'ichiro Tomonaga\n",
      "Julian Schwinger\n",
      "Rudolf Ludwig Moessbauer\n",
      "Erwin Schroedinger\n",
      "Paul Dirac\n",
      "Maria Sklodowska-Curie\n",
      "Pierre Curie\n"
     ]
    }
   ],
   "source": [
    "translit_dict = {\n",
    "    \"ä\" : \"ae\",\n",
    "    \"ö\" : \"oe\",\n",
    "    \"ü\" : \"ue\",\n",
    "    \"Ä\" : \"Ae\",\n",
    "    \"Ö\" : \"Oe\",\n",
    "    \"Ü\" : \"Ue\", \n",
    "    \"ł\" : \"l\",\n",
    "    \"ō\" : \"o\",\n",
    "}\n",
    "\n",
    "with open(\"data.csv\", 'r', encoding='utf8') as csvfile:\n",
    "    lines = csvfile.readlines()\n",
    "\n",
    "# Strip off the newline from the end of each line\n",
    "lines = [line.rstrip() for line in lines]\n",
    "    \n",
    "# Split each line based on the delimiter (which, in this case, is the comma) \n",
    "lines = [line.split(',') for line in lines]\n",
    "\n",
    "# Separate the header from the data\n",
    "header = lines[0]\n",
    "lines = lines[1:]\n",
    "    \n",
    "# Find \"name\" within the header\n",
    "name_index = header.index(\"name\")\n",
    "\n",
    "# Extract the names from the rows\n",
    "unicode_names = []\n",
    "for line in lines:\n",
    "    unicode_names.append(line[name_index])\n",
    "\n",
    "\n",
    "# Iterate over the names\n",
    "translit_names = []\n",
    "for unicode_name in unicode_names:\n",
    "    # Perform the replacements in the translit_dict\n",
    "    # HINT: ref [1]\n",
    "    for key, value in translit_dict.items():\n",
    "        unicode_name = unicode_name.replace(key, value)\n",
    "    \n",
    "    translit_names.append(unicode_name)\n",
    "\n",
    "\n",
    "# Write out the names to a file named \"data-ascii.txt\"\n",
    "# HINT: ref [2]\n",
    "with open(\"data-ascii.txt\", 'w', encoding='utf8') as f:\n",
    "    for t in translit_names:\n",
    "        f.write(t + \"\\n\")\n",
    "\n",
    "# Verify that the names were converted and written out correctly\n",
    "with open(\"data-ascii.txt\", 'r') as infile:\n",
    "    for line in infile:\n",
    "        print(line.rstrip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```\n",
    "Richard Phillips Feynman\n",
    "Shin'ichiro Tomonaga\n",
    "Julian Schwinger\n",
    "Rudolf Ludwig Moessbauer\n",
    "Erwin Schroedinger\n",
    "Paul Dirac\n",
    "Maria Sklodowska-Curie\n",
    "Pierre Curie\n",
    "```\n",
    "\n",
    "**References:**\n",
    "- [1: replace](https://docs.python.org/3.6/library/stdtypes.html#str.replace)\n",
    "- [2: file object methods](https://docs.python.org/3/tutorial/inputoutput.html#methods-of-file-objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3. Managing files in Dataverse -- Use case\n",
    "\n",
    "Conduct a search to find a comprehensive list of all Nobel Prizes awarded since 1901.\n",
    "- Source: https://www.nobelprize.org/organization/api-examples/\n",
    "\n",
    "\n",
    "Create a CSV (Comma-Separated Values) or TSV (Tab-Separated Values) file containing this data.\n",
    "\n",
    "Use this data to create a dataset in Dataverse, ensuring all relevant metadata is accurately included.\n",
    "\n",
    "In this Jupyter Notebook, create a series of cells (as many as necessary) to perform the following tasks:\n",
    "\n",
    "Download the file from Dataverse.\n",
    "\n",
    "Display the contents of the dataset.\n",
    "\n",
    "Compute basic statistics on the dataset, including:\n",
    "\n",
    "a) Count the number of Nobel Prizes awarded in each of the following categories: Chemistry, Economics, Literature, Peace, Physics, and Physiology or Medicine.\n",
    "\n",
    "b) Identify the instances where Nobel Prizes were not awarded in these categories, along with the specific years when this occurred.\n",
    "\n",
    "c) Determine how many times the Nobel Peace Prize was shared between two individuals.\n",
    "\n",
    "d) Calculate the number of times the Nobel Prize in Physiology or Medicine was shared among three individuals.\n",
    "\n",
    "Remember to comment your code thoroughly. Use markdown cells to explain and contextualize your work throughout the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Gather Nobel Prize data as CSV\n",
    "We need to first gather our data. All the Nobel Prize data can be found https://api.nobelprize.org/2.0/nobelPrizes, but we need to write code to properly put it in a CSV for further analysis. Use their API (https://app.swaggerhub.com/apis/NobelMedia/NobelMasterData/2.0#/default/get_nobelPrizes) to successfully gather all entries, especially information about the different categories, years, and laureates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to all_nobel_prizes.csv\n"
     ]
    }
   ],
   "source": [
    "## Add your code here. \n",
    "## Create a series of cells (as many as necessary)\n",
    "## Remember to comment your code thoroughly. \n",
    "## Intersperse markdown cells to explain and contextualize your work throughout the notebook.\n",
    "\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "def get_all_nobel_prizes(offset=0, limit=100):\n",
    "    base_url = \"https://api.nobelprize.org/2.0/nobelPrizes\"\n",
    "    results = []\n",
    "    \n",
    "    while True:\n",
    "        response = requests.get(f\"{base_url}?offset={offset}&limit={limit}\")\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            prizes = data.get(\"nobelPrizes\", [])\n",
    "            \n",
    "            #Stop when no more data is returned\n",
    "            if not prizes:\n",
    "                break  \n",
    "            \n",
    "            #Store each person's entry in list \"results\"\n",
    "            for prize in prizes:\n",
    "                award_year = prize.get(\"awardYear\")\n",
    "                category = prize.get(\"category\", {}).get(\"en\")\n",
    "                category_full_name = prize.get(\"categoryFullName\", {}).get(\"en\")\n",
    "                date_awarded = prize.get(\"dateAwarded\")\n",
    "                prize_amount = prize.get(\"prizeAmount\")\n",
    "                prize_amount_adjusted = prize.get(\"prizeAmountAdjusted\")\n",
    "                links = prize.get(\"links\", {}).get(\"href\")\n",
    "                \n",
    "                for laureate in prize.get(\"laureates\", []):\n",
    "                    results.append([\n",
    "                        award_year,\n",
    "                        category,\n",
    "                        category_full_name,\n",
    "                        date_awarded,\n",
    "                        prize_amount,\n",
    "                        prize_amount_adjusted,\n",
    "                        links,\n",
    "                        laureate.get(\"id\"),\n",
    "                        laureate.get(\"knownName\", {}).get(\"en\"),\n",
    "                        laureate.get(\"sortOrder\")\n",
    "                    ])\n",
    "            \n",
    "            #Request next batch of results from API\n",
    "            offset += limit  \n",
    "        else:\n",
    "            print(\"Failed to retrieve data\")\n",
    "            break\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "data = get_all_nobel_prizes()\n",
    "with open(\"all_nobel_prizes.csv\", \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"awardYear\", \"category\", \"categoryFullName\", \"dateAwarded\", \"prizeAmount\", \"prizeAmountAdjusted\", \"linksHref\", \"laureateID\", \"laureateName\", \"laureateSortOrder\"])\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(\"Data saved to all_nobel_prizes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>awardYear</th>\n",
       "      <th>category</th>\n",
       "      <th>categoryFullName</th>\n",
       "      <th>dateAwarded</th>\n",
       "      <th>prizeAmount</th>\n",
       "      <th>prizeAmountAdjusted</th>\n",
       "      <th>linksHref</th>\n",
       "      <th>laureateID</th>\n",
       "      <th>laureateName</th>\n",
       "      <th>laureateSortOrder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1901</td>\n",
       "      <td>Chemistry</td>\n",
       "      <td>The Nobel Prize in Chemistry</td>\n",
       "      <td>1901-11-12</td>\n",
       "      <td>150782</td>\n",
       "      <td>9704878</td>\n",
       "      <td>https://api.nobelprize.org/2/nobelPrize/che/1901</td>\n",
       "      <td>160</td>\n",
       "      <td>Jacobus H. van 't Hoff</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1901</td>\n",
       "      <td>Literature</td>\n",
       "      <td>The Nobel Prize in Literature</td>\n",
       "      <td>1901-11-14</td>\n",
       "      <td>150782</td>\n",
       "      <td>9704878</td>\n",
       "      <td>https://api.nobelprize.org/2/nobelPrize/lit/1901</td>\n",
       "      <td>569</td>\n",
       "      <td>Sully Prudhomme</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1901</td>\n",
       "      <td>Peace</td>\n",
       "      <td>The Nobel Peace Prize</td>\n",
       "      <td>1901-12-10</td>\n",
       "      <td>150782</td>\n",
       "      <td>9704878</td>\n",
       "      <td>https://api.nobelprize.org/2/nobelPrize/pea/1901</td>\n",
       "      <td>462</td>\n",
       "      <td>Henry Dunant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1901</td>\n",
       "      <td>Peace</td>\n",
       "      <td>The Nobel Peace Prize</td>\n",
       "      <td>1901-12-10</td>\n",
       "      <td>150782</td>\n",
       "      <td>9704878</td>\n",
       "      <td>https://api.nobelprize.org/2/nobelPrize/pea/1901</td>\n",
       "      <td>463</td>\n",
       "      <td>Frédéric Passy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1901</td>\n",
       "      <td>Physics</td>\n",
       "      <td>The Nobel Prize in Physics</td>\n",
       "      <td>1901-11-12</td>\n",
       "      <td>150782</td>\n",
       "      <td>9704878</td>\n",
       "      <td>https://api.nobelprize.org/2/nobelPrize/phy/1901</td>\n",
       "      <td>1</td>\n",
       "      <td>Wilhelm Conrad Röntgen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>2024</td>\n",
       "      <td>Peace</td>\n",
       "      <td>The Nobel Peace Prize</td>\n",
       "      <td>2024-10-11</td>\n",
       "      <td>11000000</td>\n",
       "      <td>11000000</td>\n",
       "      <td>https://api.nobelprize.org/2/nobelPrize/pea/2024</td>\n",
       "      <td>1043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>2024</td>\n",
       "      <td>Physics</td>\n",
       "      <td>The Nobel Prize in Physics</td>\n",
       "      <td>2024-10-08</td>\n",
       "      <td>11000000</td>\n",
       "      <td>11000000</td>\n",
       "      <td>https://api.nobelprize.org/2/nobelPrize/phy/2024</td>\n",
       "      <td>1037</td>\n",
       "      <td>John J. Hopfield</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>2024</td>\n",
       "      <td>Physics</td>\n",
       "      <td>The Nobel Prize in Physics</td>\n",
       "      <td>2024-10-08</td>\n",
       "      <td>11000000</td>\n",
       "      <td>11000000</td>\n",
       "      <td>https://api.nobelprize.org/2/nobelPrize/phy/2024</td>\n",
       "      <td>1038</td>\n",
       "      <td>Geoffrey Hinton</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>2024</td>\n",
       "      <td>Physiology or Medicine</td>\n",
       "      <td>The Nobel Prize in Physiology or Medicine</td>\n",
       "      <td>2024-10-07</td>\n",
       "      <td>11000000</td>\n",
       "      <td>11000000</td>\n",
       "      <td>https://api.nobelprize.org/2/nobelPrize/med/2024</td>\n",
       "      <td>1035</td>\n",
       "      <td>Victor Ambros</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>2024</td>\n",
       "      <td>Physiology or Medicine</td>\n",
       "      <td>The Nobel Prize in Physiology or Medicine</td>\n",
       "      <td>2024-10-07</td>\n",
       "      <td>11000000</td>\n",
       "      <td>11000000</td>\n",
       "      <td>https://api.nobelprize.org/2/nobelPrize/med/2024</td>\n",
       "      <td>1036</td>\n",
       "      <td>Gary Ruvkun</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1012 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      awardYear                category  \\\n",
       "0          1901               Chemistry   \n",
       "1          1901              Literature   \n",
       "2          1901                   Peace   \n",
       "3          1901                   Peace   \n",
       "4          1901                 Physics   \n",
       "...         ...                     ...   \n",
       "1007       2024                   Peace   \n",
       "1008       2024                 Physics   \n",
       "1009       2024                 Physics   \n",
       "1010       2024  Physiology or Medicine   \n",
       "1011       2024  Physiology or Medicine   \n",
       "\n",
       "                               categoryFullName dateAwarded  prizeAmount  \\\n",
       "0                  The Nobel Prize in Chemistry  1901-11-12       150782   \n",
       "1                 The Nobel Prize in Literature  1901-11-14       150782   \n",
       "2                         The Nobel Peace Prize  1901-12-10       150782   \n",
       "3                         The Nobel Peace Prize  1901-12-10       150782   \n",
       "4                    The Nobel Prize in Physics  1901-11-12       150782   \n",
       "...                                         ...         ...          ...   \n",
       "1007                      The Nobel Peace Prize  2024-10-11     11000000   \n",
       "1008                 The Nobel Prize in Physics  2024-10-08     11000000   \n",
       "1009                 The Nobel Prize in Physics  2024-10-08     11000000   \n",
       "1010  The Nobel Prize in Physiology or Medicine  2024-10-07     11000000   \n",
       "1011  The Nobel Prize in Physiology or Medicine  2024-10-07     11000000   \n",
       "\n",
       "      prizeAmountAdjusted                                         linksHref  \\\n",
       "0                 9704878  https://api.nobelprize.org/2/nobelPrize/che/1901   \n",
       "1                 9704878  https://api.nobelprize.org/2/nobelPrize/lit/1901   \n",
       "2                 9704878  https://api.nobelprize.org/2/nobelPrize/pea/1901   \n",
       "3                 9704878  https://api.nobelprize.org/2/nobelPrize/pea/1901   \n",
       "4                 9704878  https://api.nobelprize.org/2/nobelPrize/phy/1901   \n",
       "...                   ...                                               ...   \n",
       "1007             11000000  https://api.nobelprize.org/2/nobelPrize/pea/2024   \n",
       "1008             11000000  https://api.nobelprize.org/2/nobelPrize/phy/2024   \n",
       "1009             11000000  https://api.nobelprize.org/2/nobelPrize/phy/2024   \n",
       "1010             11000000  https://api.nobelprize.org/2/nobelPrize/med/2024   \n",
       "1011             11000000  https://api.nobelprize.org/2/nobelPrize/med/2024   \n",
       "\n",
       "      laureateID            laureateName  laureateSortOrder  \n",
       "0            160  Jacobus H. van 't Hoff                  1  \n",
       "1            569         Sully Prudhomme                  1  \n",
       "2            462            Henry Dunant                  1  \n",
       "3            463          Frédéric Passy                  2  \n",
       "4              1  Wilhelm Conrad Röntgen                  1  \n",
       "...          ...                     ...                ...  \n",
       "1007        1043                     NaN                  1  \n",
       "1008        1037        John J. Hopfield                  1  \n",
       "1009        1038         Geoffrey Hinton                  2  \n",
       "1010        1035           Victor Ambros                  1  \n",
       "1011        1036             Gary Ruvkun                  2  \n",
       "\n",
       "[1012 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Just to check the contents of the csv\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"all_nobel_prizes.csv\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get 1012 entries. According to the official website (https://www.nobelprize.org/prizes/lists/all-nobel-prizes/), the Nobel Prizes were \"awarded 627 times to 1012 people and organisations.\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Put data on Dataverse\n",
    "The Nobel Peace prize CSV file is uploaded to Harvard Dataverse and shared publicly. The link is https://doi.org/10.7910/DVN/QCHRYN. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Analysis\n",
    "Let's answer the following questions using the CSV file.\n",
    "\n",
    "a) Count the number of Nobel Prizes awarded in each of the following categories: Chemistry, Economics, Literature, Peace, Physics, and Physiology or Medicine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 category  num_prizes\n",
      "0               Chemistry         116\n",
      "1       Economic Sciences          56\n",
      "2              Literature         117\n",
      "3                   Peace         105\n",
      "4                 Physics         118\n",
      "5  Physiology or Medicine         115\n"
     ]
    }
   ],
   "source": [
    "#Count the number of occurrences of a specific year and category\n",
    "#Reframes df to count each category and year pair as one award\n",
    "category_counts = df.groupby([\"awardYear\", \"category\"]).size().reset_index(name=\"num_prizes\")\n",
    "category_counts = category_counts.groupby(\"category\").size().reset_index(name=\"num_prizes\")\n",
    "print(category_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Identify the instances where Nobel Prizes were not awarded in these categories, along with the specific years when this occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing year per category:\n",
      "Chemistry: [1916, 1917, 1919, 1924, 1933, 1940, 1941, 1942]\n",
      "Economic Sciences: [1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910, 1911, 1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1926, 1927, 1928, 1929, 1930, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939, 1940, 1941, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968]\n",
      "Literature: [1914, 1918, 1935, 1940, 1941, 1942, 1943]\n",
      "Peace: [1914, 1915, 1916, 1918, 1923, 1924, 1928, 1932, 1939, 1940, 1941, 1942, 1943, 1948, 1955, 1956, 1966, 1967, 1972]\n",
      "Physics: [1916, 1931, 1934, 1940, 1941, 1942]\n",
      "Physiology or Medicine: [1915, 1916, 1917, 1918, 1921, 1925, 1940, 1941, 1942]\n"
     ]
    }
   ],
   "source": [
    "missing_awards = {}\n",
    "all_years = set(range(1901, 2025))\n",
    "\n",
    "\n",
    "for category in df[\"category\"].unique():\n",
    "    missing_awards[category] = []\n",
    "    awarded_years = set(df[df[\"category\"] == category][\"awardYear\"].unique())\n",
    "    not_awarded_years = all_years - awarded_years\n",
    "    \n",
    "    #Add all missing years to the category\n",
    "    for year in not_awarded_years:\n",
    "        missing_awards[category].append(int(year))\n",
    "\n",
    "    missing_awards[category].sort()\n",
    "\n",
    "sorted_missing_awards = dict(sorted(missing_awards.items()))\n",
    "\n",
    "print(\"Missing year per category:\")\n",
    "for key, value in sorted_missing_awards.items():\n",
    "    print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Determine how many times the Nobel Peace Prize was shared between two individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of times the Nobel Peace Prize was shared between 2 individuals:  31\n"
     ]
    }
   ],
   "source": [
    "#Filter df by \"Peace\" category and reframe to have counts of specific year and category\n",
    "#Duplicate year and category pairs means multiple individuals\n",
    "peace_prize_shared = df[(df[\"category\"] == \"Peace\")].groupby([\"awardYear\", \"category\"]).size()\n",
    "two_winner_count = peace_prize_shared[peace_prize_shared == 2].count()\n",
    "print(\"Number of times the Nobel Peace Prize was shared between 2 individuals: \", two_winner_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Calculate the number of times the Nobel Prize in Physiology or Medicine was shared among three individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of times the Nobel Prize in Physiology or Medicine was shared among 3 individuals:  39\n"
     ]
    }
   ],
   "source": [
    "#Filter df by \"Physiology or Medicine\" category and reframe to have counts of specific year and category\n",
    "#Duplicate year and category pairs means multiple individuals\n",
    "medicine_prize_shared = df[(df[\"category\"] == \"Physiology or Medicine\")].groupby([\"awardYear\", \"category\"]).size()\n",
    "three_winner_count = medicine_prize_shared[medicine_prize_shared == 3].count()\n",
    "print(\"Number of times the Nobel Prize in Physiology or Medicine was shared among 3 individuals: \", three_winner_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4. Write the comprehensive README files for Problem 3\n",
    "\n",
    "**Note:** These directions are for a README file for your assignments. An extensive README file should be used for your project. \n",
    "\n",
    "***Write the comprehensive README files for Assginemnt 1***\n",
    "\n",
    "A comprehensive README file on GitHub is the primary information source for anyone exploring your repository. It is essential for clearly conveying your assignment's purpose, setup, and usage.\n",
    "\n",
    "Key elements of a comprehensive README for an assignment include:\n",
    "\n",
    "Assignment title: This should clearly state the name of your project.\n",
    "\n",
    "Assignment description: Provide a concise overview of what the project entails. This section should explain the project's usefulness and the problems it addresses.\n",
    "\n",
    "Installation instructions: Offer detailed steps for setting up the project. This includes any prerequisites, dependencies, and a step-by-step guide to operationalizing the project.\n",
    "\n",
    "Use: Give clear instructions on how to use the project. Enhance this section with practical examples, including code snippets, screenshots, or videos.\n",
    "\n",
    "Contact information: Detail how to contact you. This could be through email.\n",
    "\n",
    "Acknowledgments: Credit any individuals, organizations, or other entities contributing significantly to the assignment.\n",
    "Use APA citation style.\n",
    "\n",
    "**Add the README file to the GitHub repository with the solution of Problems 3.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Free-Form Questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Given that your solutions for Problems 1 and 2 likely have similar code components, you may have found yourself copying and pasting code from Problem 1 to Problem 2. To streamline this, consider refactoring the `parse_delimited_file` function so that it can be effectively utilized in both problems. Write the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows of data: 8\n",
      "Number of cols: 3\n",
      "Average Age: 70.875\n",
      "\n",
      "Richard Phillips Feynman\n",
      "Shin'ichiro Tomonaga\n",
      "Julian Schwinger\n",
      "Rudolf Ludwig Moessbauer\n",
      "Erwin Schroedinger\n",
      "Paul Dirac\n",
      "Maria Sklodowska-Curie\n",
      "Pierre Curie\n"
     ]
    }
   ],
   "source": [
    "translit_dict = {\n",
    "    \"ä\" : \"ae\",\n",
    "    \"ö\" : \"oe\",\n",
    "    \"ü\" : \"ue\",\n",
    "    \"Ä\" : \"Ae\",\n",
    "    \"Ö\" : \"Oe\",\n",
    "    \"Ü\" : \"Ue\", \n",
    "    \"ł\" : \"l\",\n",
    "    \"ō\" : \"o\",\n",
    "}\n",
    "\n",
    "def parse_delimited_file(filename, col_filter, delimiter=\",\"):\n",
    "    # Open and read in all lines of the file\n",
    "    with open(filename, 'r', encoding='utf8') as dsvfile:\n",
    "        lines = dsvfile.readlines()\n",
    "\n",
    "    # Strip off the newline from the end of each line\n",
    "    lines = [line.rstrip() for line in lines]\n",
    "\n",
    "    # Split each line based on the delimiter (which, in this case, is the comma)\n",
    "    lines = [line.split(delimiter) for line in lines]\n",
    "    \n",
    "    # Separate the header from the data\n",
    "    header = lines[0]\n",
    "    lines = lines[1:]\n",
    "\n",
    "    # Find whatever column filter (\"age\", \"name\") within the header\n",
    "    index = header.index(col_filter)\n",
    "\n",
    "    # Calculate the number of data rows and columns\n",
    "    num_data_rows = len(lines)\n",
    "    num_data_cols = len(lines[0])\n",
    "    \n",
    "    #For Problem 1\n",
    "    if col_filter == \"age\":\n",
    "      # Sum the \"age\" values\n",
    "      age_total = 0\n",
    "      for line in lines:\n",
    "          age_total += int(line[index])\n",
    "          \n",
    "      # Calculate the average age\n",
    "      ave_age = age_total / num_data_rows\n",
    "    \n",
    "      # Print the results\n",
    "      print(\"Number of rows of data: {}\".format(num_data_rows))\n",
    "      print(\"Number of cols: {}\".format(num_data_cols))\n",
    "      print(\"Average Age: {}\".format(ave_age))\n",
    "    \n",
    "\n",
    "    #For Problem 2\n",
    "    elif col_filter == \"name\":\n",
    "        unicode_names = []\n",
    "        for line in lines:\n",
    "            unicode_names.append(line[index])\n",
    "        \n",
    "\n",
    "        translit_names = []\n",
    "        for unicode_name in unicode_names:\n",
    "            # Perform the replacements in the translit_dict\n",
    "            for key, value in translit_dict.items():\n",
    "                unicode_name = unicode_name.replace(key, value)\n",
    "            \n",
    "            translit_names.append(unicode_name)\n",
    "\n",
    "        with open(\"data-ascii.txt\", 'w', encoding='utf8') as f:\n",
    "            for t in translit_names:\n",
    "                f.write(t + \"\\n\")\n",
    "\n",
    "        with open(\"data-ascii.txt\", 'r') as infile:\n",
    "            for line in infile:\n",
    "                print(line.rstrip())\n",
    "\n",
    "\n",
    "#Problem 1\n",
    "parse_delimited_file('data.csv', \"age\")\n",
    "\n",
    "print()\n",
    "\n",
    "#Problem 2\n",
    "parse_delimited_file(\"data.csv\", \"name\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. Investigate whether there are any pre-existing Python packages that could assist in solving Problems 1 and 2. If such packages are available, modify your solutions to incorporate them, enhancing efficiency and possibly reducing the amount of custom code required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows of data: 8\n",
      "Number of cols: 3\n",
      "Average Age: 70.875\n",
      "\n",
      "Richard Phillips Feynman\n",
      "Shin'ichiro Tomonaga\n",
      "Julian Schwinger\n",
      "Rudolf Ludwig Mossbauer\n",
      "Erwin Schrodinger\n",
      "Paul Dirac\n",
      "Maria Sklodowska-Curie\n",
      "Pierre Curie\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "\n",
    "def parse_delimited_file(filename, col_filter, delimiter=\",\"):\n",
    "    df = pd.read_csv(filename, delimiter=delimiter)\n",
    "\n",
    "    # Problem 1\n",
    "    if col_filter == \"age\":\n",
    "        ave_age = df[\"age\"].mean()\n",
    "        print(f\"Number of rows of data: {len(df)}\")\n",
    "        print(f\"Number of cols: {df.shape[1]}\")\n",
    "        print(f\"Average Age: {ave_age}\")\n",
    "\n",
    "    # Problem 2\n",
    "    elif col_filter == \"name\":\n",
    "        df[\"name\"] = df[\"name\"].apply(unidecode)  #Convert Unicode to ASCII\n",
    "        df[\"name\"].to_csv(\"data-ascii.txt\", index=False, header=False, encoding='utf8')\n",
    "\n",
    "        # Print transliterated names\n",
    "        with open(\"data-ascii.txt\", 'r', encoding='utf-8') as infile:\n",
    "            for line in infile:\n",
    "                print(line.rstrip())\n",
    "\n",
    "#Problem 1\n",
    "parse_delimited_file('data.csv', \"age\")\n",
    "print()\n",
    "#Problem 2\n",
    "parse_delimited_file(\"data.csv\", \"name\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas - easy to read csv (https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)\n",
    "- Unidecode - convert unicode to ASCII instead of manually doing it (https://pypi.org/project/Unidecode/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live Chat: What we learned from 5 million books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After watching the talk of Jean-Baptiste Michel and Erez Lieberman Aiden who told us about “What we learned from 5 million books”\n",
    "https://www.ted.com/talks/jean_baptiste_michel_erez_lieberman_aiden_what_we_learned_from_5_million_books\n",
    "\n",
    "Answer these questions related to the talk:\n",
    "\n",
    "- What is the take-away of this talk? Summarize it in up to 3 sentences.\n",
    "\n",
    "- What are metadata?\n",
    "\n",
    "- What is a n-gram?\n",
    "\n",
    "- What is the suppression index? \n",
    "\n",
    "- What is culturomics? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google digitized 5 million books and created Google Labs' Ngram Viewer, allowing researchers to compute statistics about books. Michel and Aiden were able to find cultural trends across centuries from word usage to censorship. More historical records are being digitized and the results will transform our understanding of language, history, and culture.\n",
    "\n",
    "- Metadata - Information about one or more aspects of the data like where it's published.\n",
    "- N-gram - A sequence of n words. In this context, they help measure of cultural trends.\n",
    "- Supression index - Victims of suppression from 0 to 100. Talked about more/less than they should be.\n",
    "- Culturomics - Application of massive scale data collection and analysis to the study of human culture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your reflect on this lecture and assignment:\n",
    "\n",
    "Q1 **Resource Utilization in Problem 1:**\n",
    "\n",
    "How many different external resources (such as websites or books) did you consult while working on Problem 1? Please list these resources.\n",
    "\n",
    "Q2 **Tools and Packages Used in Problem 2:**\n",
    "\n",
    "Can you quantify the number of external tools or Python packages you utilized in Problem 2? Please list these tools or packages.\n",
    "\n",
    "Q3 **Debugging in Problem 1:**\n",
    "\n",
    "How many times did you encounter and resolve errors or bugs in Problem 1? Detail each instance.\n",
    "\n",
    "Q4 **Debugging in Problem 2:**\n",
    "\n",
    "What was the total number of debugging instances in Problem 2? Please describe each instance.\n",
    "\n",
    "Q5 **Learning and Insights:**\n",
    "\n",
    "What are the key lessons or insights you gained from solving these problems? How do you plan to apply these insights to future coding projects or problem-solving situations?\n",
    "\n",
    "Q6 **Collaborative Experiences:**\n",
    "\n",
    "If you worked with others, describe how collaboration affected your approach to the problems. Could you provide an example of how you assisted a peer or how a peer's advice was beneficial to you?\n",
    "\n",
    "**Important Note:** Your responses to these questions are as critical as your solutions for Problems 1 and 2. Brief answers or responses limited to just a few words will be considered inadequate and will negatively impact the overall grading of your assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write here your answers, enumarating them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  The only resources I used for problm 1 were the ones listed in the provided references. The links in the references all lead to docs.python.org.\n",
    "\n",
    "2. The number of external tools and Python packages I used in the original problem is zero. For the free-form question about shortening the function, I used two packages: pandas and unidecode.\n",
    "\n",
    "3. All of my debugging happened in problem 1a since 1b uses the same function without any changes. I tried to code without directly looking up the references so my bug fixes were all silly mistakes. For example, I forgot the \"age\" values are strings, so I forgot to convert them to integers. The other silly mistake was using split instead of rstrip. I did look at the references and miscounted, so I thought I had to use split to remove the new lines.\n",
    "\n",
    "4. The debugging was even less than problem 1 since I could copy most of my code from problem 1's solution. The only silly bug was incorrectly writing the for loop for the translit_dict to replace the unicode with ASCII. I forgot that the dictionary needs .items() at the end to successfully access the key and value. \n",
    "\n",
    "5. Overall, these problems were not difficult. They were a nice refresher for built-in Python functions. My key lesson is that I should just read the documentation when I forget syntax. I try to brute force myself to remember how a function call is written due to my pride, but next time I should just bite the bullet and look it up. Documentation exists for a reason. Also, I'm so used to processing csvs with pandas, so it was a good exercise to do it with built-in Python functions. Staying fresh with rstrip(), index(), etc could come in handy in future coding projects.\n",
    "\n",
    "\n",
    "6. I did not work with others, but I would imagine it would be during the data collection for problem 3 if I did. I'm not the best at using REST API, so I can see struggling to write the calls to get all the data I need. I tend to do things less efficiently but simpler to do, but sometimes it's better to put in some more work to save time overall."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
